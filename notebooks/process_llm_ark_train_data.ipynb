{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00709a-01b0-45aa-8550-b6937fdc95bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from model.utils import check_dir\n",
    "from walker.Data import DataLoader\n",
    "from model.bart import Generator\n",
    "from model.partner import Partner\n",
    "from model.ppo_trick import PPO\n",
    "from walker.Graph import KnowledgeGraph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46feddc-191c-4aec-8bcb-39b0bf9dcd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"Hyperparameter Setting for PPO-discrete\")\n",
    "parser.add_argument('--exp_name', default=\"OpenDialKG\", type=str)\n",
    "parser.add_argument('--data_dir', default=\"datasets\", type=str)\n",
    "parser.add_argument('--dataset', default=\"OpenDialKG\", type=str)\n",
    "parser.add_argument('--output_dir', default=\"output\", type=str)\n",
    "parser.add_argument('--pair_list', default=\"\", type=str)\n",
    "parser.add_argument('--mode', default=\"train\", type=str)\n",
    "parser.add_argument('--model', default=\"checkpoint\", type=str)\n",
    "parser.add_argument('--character', default=\"Assistant\", type=str, help=\"Target / MultiHop / Assistant / User / Reason\")\n",
    "parser.add_argument('--ablation', default=\"Proposed\", type=str, help=\"Proposed / Utterance / Context\")\n",
    "parser.add_argument('--use_trans_d', type=bool, default=True)\n",
    "parser.add_argument('--show_dialog', type=bool, default=False)\n",
    "parser.add_argument('--max_episodes', default=-1, type=int)\n",
    "parser.add_argument('--max_patience', default=10, type=int)\n",
    "parser.add_argument('--max_turns', default=8, type=int)\n",
    "parser.add_argument('--state_embed_size', default=4096, type=int)\n",
    "parser.add_argument(\"--use_bias\", type=bool, default=False, help=\"whether to use bias for actor\")\n",
    "parser.add_argument(\"--fp16\", type=bool, default=False, help=\"whether to use fp16\")\n",
    "parser.add_argument(\"--bf16\", type=bool, default=True, help=\"whether to use bf16\")\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=4096, help=\"The number of neurons in hidden layers of the neural network\")\n",
    "parser.add_argument('--relation_embed_size', default=200, type=int)\n",
    "parser.add_argument('--entity_embed_size', default=200, type=int)\n",
    "parser.add_argument('--max_out', default=50, type=int)\n",
    "parser.add_argument('--max_step_length', default=2, type=int)\n",
    "parser.add_argument('--seed', default=3407, type=int)\n",
    "parser.add_argument('--adversarial', type=str, default=\"\")\n",
    "parser.add_argument('--train_times', default=8, type=int)\n",
    "parser.add_argument('--test_times', default=20, type=int)\n",
    "parser.add_argument(\"--epoch\", type=int, default=8, help=\"Maximum number of training steps\")\n",
    "parser.add_argument(\"--evaluate_freq\", type=float, default=5,\n",
    "                    help=\"Evaluate the policy every 'evaluate_freq' steps\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=4096, help=\"Batch size\")\n",
    "parser.add_argument(\"--mini_batch_size\", type=int, default=1024, help=\"Minibatch size\")\n",
    "parser.add_argument(\"--train_batch_size\", type=int, default=16, help=\"Batch size\")\n",
    "parser.add_argument(\"--test_batch_size\", type=int, default=128, help=\"Batch size\")\n",
    "parser.add_argument(\"--gradient_accumulation\", type=int, default=1, help=\"Batch size\")\n",
    "parser.add_argument(\"--stater_type\", type=str, default=\"llama\", help=\"stater type: llama, flant5-large, bert-base\")\n",
    "parser.add_argument(\"--instruction_type\", type=str, default=\"1\", help=\"0: alpaca v1 prompt; 1: gpt normal prompt; 2: uninstruction prompt\")\n",
    "parser.add_argument(\"--stater_path\", type=str, default=\"/root/autodl-tmp/huggingface/hub/models--NousResearch--Llama-2-7b-chat-hf/models--NousResearch--Llama-2-7b-chat-hf/snapshots/37892f30c23786c0d5367d80481fa0d9fba93cf8\", help=\"stater path\")\n",
    "parser.add_argument(\"--actor_path\", type=str, default=\"\", help=\"actor path\")\n",
    "parser.add_argument(\"--actor_checkpoint_path\", type=str, default=\"\")\n",
    "parser.add_argument(\"--rl_train_data_path\", type=str, default=\"datasets/OpenDialKG/Reason/train_type_1.json\")\n",
    "parser.add_argument(\"--rl_valid_data_path\", type=str, default=\"datasets/OpenDialKG/Reason/valid_type_1.json\")\n",
    "parser.add_argument(\"--rl_test_data_path\", type=str, default=\"datasets/OpenDialKG/Reason/test_type_1.json\")\n",
    "parser.add_argument(\"--entity_embedding_path\", type=str, default=\"checkpoint/OpenDialKG/TransE/entity.pth\", help=\"\")\n",
    "parser.add_argument(\"--relation_embedding_path\", type=str, default=\"checkpoint/OpenDialKG/TransE/relation.pth\", help=\"actor checkpoint path\")\n",
    "parser.add_argument(\"--positive_reward\", type=float, default=1, help=\"positive reward\")\n",
    "parser.add_argument(\"--negative_reward\", type=float, default=-1, help=\"negative reward\")\n",
    "parser.add_argument(\"--coh_weight\", type=float, default=0.0, help=\"weight of coherence reward\")\n",
    "parser.add_argument(\"--sim_weight\", type=float, default=0.0, help=\"weight of similarity reward\")\n",
    "parser.add_argument(\"--tar_weight\", type=float, default=1, help=\"weight of target reward\")\n",
    "parser.add_argument(\"--lr_a\", type=float, default=5e-5, help=\"Learning rate of actor\")\n",
    "parser.add_argument(\"--lr_c\", type=float, default=5e-5, help=\"Learning rate of critic\")\n",
    "parser.add_argument(\"--gamma\", type=float, default=0.95, help=\"Discount factor\")\n",
    "parser.add_argument(\"--lamda\", type=float, default=0.95, help=\"GAE parameter\")\n",
    "parser.add_argument(\"--epsilon\", type=float, default=0.2, help=\"PPO clip parameter\")\n",
    "parser.add_argument(\"--K_epochs\", type=int, default=10, help=\"PPO parameter\")\n",
    "parser.add_argument(\"--use_state_norm\", type=bool, default=False, help=\"Trick 2:state normalization\")\n",
    "parser.add_argument(\"--use_adv_norm\", type=bool, default=True, help=\"Trick 1:advantage normalization\")\n",
    "parser.add_argument(\"--entropy_coef\", type=float, default=0.01, help=\"Trick 5: policy entropy\")\n",
    "parser.add_argument(\"--use_lr_decay\", type=bool, default=True, help=\"Trick 6:learning rate Decay\")\n",
    "parser.add_argument(\"--use_grad_clip\", type=bool, default=True, help=\"Trick 7: Gradient clip\")\n",
    "parser.add_argument(\"--use_orthogonal_init\", type=bool, default=True, help=\"Trick 8: orthogonal initialization\")\n",
    "parser.add_argument(\"--set_adam_eps\", type=float, default=True, help=\"Trick 9: set Adam epsilon=1e-5\")\n",
    "parser.add_argument(\"--use_tanh\", type=float, default=True, help=\"Trick 10: tanh activation function\")\n",
    "\n",
    "option = parser.parse_args([])\n",
    "\n",
    "option.graph_dir = os.path.join(option.data_dir, option.dataset, \"Graph\")\n",
    "option.generator_dir = os.path.join(option.data_dir, option.dataset, \"Generator\")\n",
    "option.reason_dir = os.path.join(option.data_dir, option.dataset, \"Reason\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ff7f2-dae6-4e37-8688-502d25a3638f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_relation 1383\n",
      "num_entity 100719\n",
      "constructing graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20576/20576 [00:00<00:00, 198241.36it/s]\n",
      "100%|██████████| 1172553/1172553 [01:06<00:00, 17638.12it/s]\n",
      "100%|██████████| 100717/100717 [00:01<00:00, 84256.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more_out_count 2204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(option, \"Assistant\")\n",
    "graph = KnowledgeGraph(option, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ffa18-0d6d-4444-8bc2-db4e7f8c8fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(option.generator_dir, \"train.json\")\n",
    "valid_data_path = os.path.join(option.generator_dir, \"valid.json\")\n",
    "test_data_path = os.path.join(option.generator_dir, \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e136d-7a5b-400f-8544-e7e48963f939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(train_data_path, \"r\", encoding=\"utf8\") as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96c74c-7ab1-4f87-9a0a-037cfea68fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(valid_data_path, \"r\", encoding=\"utf8\") as f:\n",
    "    valid_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa2967-f171-4ccd-a01c-dce13f0e0a80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2807 column 14 (char 97287)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(test_data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     test_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2807 column 14 (char 97287)"
     ]
    }
   ],
   "source": [
    "# with open(test_data_path, \"r\", encoding=\"utf8\") as f:\n",
    "#     test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab53d97-6c42-423c-a268-4d8fc7a7d653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.extend(valid_data)\n",
    "\n",
    "# train_data.extend(test_data)\n",
    "\n",
    "data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a248f51-4267-4b6f-b62f-08ba51c11304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getout(current):\n",
    "    arr = []\n",
    "    ce = data_loader.entity2num[current]\n",
    "    outs = graph.get_out(ce)\n",
    "    for relation, target in outs.squeeze().cpu().numpy():\n",
    "        r = data_loader.num2relation[relation]\n",
    "        t = data_loader.num2entity[target]\n",
    "        if t != \"Pad\":\n",
    "            arr.append(f\"{current},{r},{t}\")\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4855a5-1b27-4116-8e09-c0eec9ad3766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "You are now an assistant and are answering a user's Utterance. Starting with the Current Entity as the starting point, performing one or two-hop reasoning on the knowledge graph based on the query and Dialog History, and the Path History is a set of triples that consisting of [Starting Entity, Relation, Target Entity]\n",
    "\"\"\"\n",
    "\n",
    "inputs = \"\"\"\n",
    "Dialog History: {}\n",
    "Utterance: {}\n",
    "Path History: {}\n",
    "Current Entity: {}\n",
    "Current Step: {}\n",
    "\n",
    "\n",
    "{}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "task_background = \"Performing one-hop reasoning on the knowledge graph.\"\n",
    "\n",
    "normal_example = \"\"\"\n",
    "\n",
    "### Examples\n",
    "\n",
    "Environment:\n",
    "Dialog History: []\n",
    "Utterance: What do you think about the Washinton Redskins? Are you a fan?\n",
    "Path History: ['Washington Redskins,~Team coached,Mike Shanahan']\n",
    "Current Entity: Washington Redskins\n",
    "Current Step: 2\n",
    "\n",
    "Response:\n",
    "Washington Redskins,~Team coached,Mike Shanahan\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "opa_example=\"\"\"\n",
    "\n",
    "### Examples\n",
    "\n",
    "Environment:\n",
    "Dialog History: []\n",
    "Utterance: What do you think about the Washinton Redskins? Are you a fan?\n",
    "Path History: ['Washington Redskins,~Team coached,Mike Shanahan']\n",
    "Current Entity: Washington Redskins\n",
    "Current Step: 2\n",
    "Out Paths: ['Washington Redskins,Equal,Washington Redskins', 'Washington Redskins,~Team coached,Mike Shanahan', 'Washington Redskins,~Champion,Super Bowl XXVI', 'Washington Redskins,~Team,National Football League', \n",
    " 'Washington Redskins,~Runner-up,Super Bowl VII', 'Washington Redskins,~Team Owned,Dwight Schar', 'Washington Redskins,~Game,Mike Sellers', 'Washington Redskins,~Team coached,Jay Gruden', 'Washington Redskins,~Current team head coached,Jay Gruden', 'Washington Redskins,~Runner-up,Super Bowl XVIII', \n",
    " 'Washington Redskins,~Coaching history,Vince Lombardi', 'Washington Redskins,~Game,Jason Taylor', 'Washington Redskins,~Game,Todd Collins', \n",
    " 'Washington Redskins,~Game,Santana Moss', 'Washington Redskins,~Game,Brian Orakpo', 'Washington Redskins,~Game,Ladell Betts', 'Washington \n",
    " 'Washington Redskins,~Game,Kedric Golston']\n",
    "\n",
    "Response:\n",
    "Washington Redskins,~Team coached,Mike Shanahan\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "normal_prompt=\"\"\"\n",
    "### Task Background:\n",
    "Performing one-hop reasoning on the knowledge graph.\n",
    "\n",
    "### Instruction:\n",
    "Given the Task Background and the Environment, directly output this path in triplet format without any other content.\n",
    "\n",
    "\n",
    "### Environment:\n",
    "Dialog History: {}\n",
    "Utterance: {}\n",
    "Path History: {}\n",
    "Current Entity: {}\n",
    "Current Step: {}\n",
    "\n",
    "\n",
    "{}\n",
    "\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "out_path_aware_prompt=\"\"\"\n",
    "### Task Background:\n",
    "Performing one-hop reasoning on the knowledge graph.\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "Given the Task Background and the Environment, please choose a properate KG path from a set of Out Paths, directly output this path in triplet format without any other content.\n",
    "\n",
    "\n",
    "### Environment:\n",
    "Dialog History: {}\n",
    "Utterance: {}\n",
    "Path History: {}\n",
    "Current Entity: {}\n",
    "Current Step: {}\n",
    "Out Paths: {}\n",
    "\n",
    "\n",
    "{}\n",
    "\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "## RL data\n",
    "\n",
    "alpaca_format = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "Write a response that appropriately completes the request.\\n\\n\n",
    "### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047561e-6490-4393-92e6-ead647742830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_threshold = 1600 - len(alpaca_format.format(instruction=instruction, input=\"\"))\n",
    "\n",
    "rl_data = []\n",
    "rl_data_len_path_1 = []\n",
    "rl_data_len_path_2 = []\n",
    "lens = []\n",
    "\n",
    "if option.instruction_type == \"0\":\n",
    "    rl_lens_threshold  = base_threshold + len(alpaca_format.format(instruction=instruction, input=\"\"))\n",
    "elif option.instruction_type == \"1\":\n",
    "    rl_lens_threshold  = base_threshold + len(normal_prompt)\n",
    "else:\n",
    "    rl_lens_threshold  = base_threshold\n",
    "\n",
    "path_len_distribution = [0] * 2\n",
    "for i in data:\n",
    "    context = []\n",
    "    path_history = []\n",
    "    for item in i[\"dialog\"]:\n",
    "        sender = item[\"sender\"]\n",
    "        text = item[\"text\"]\n",
    "        label = item[\"label\"]\n",
    "        if \"current_entity\" in item.keys() and sender == \"user\":\n",
    "            path = item[\"path\"]\n",
    "            ce = path[0][0]\n",
    "            te = path[0][-1]\n",
    "            # if len(path) == 1:\n",
    "            #     continue\n",
    "            # 去掉不连贯数据\n",
    "            if len(path) == 2 and path[0][-1] != path[1][0]: \n",
    "                continue\n",
    "            # s_p = ','.join(path[0])\n",
    "            sample = {\n",
    "                \"input\": \"\",\n",
    "                \"dialog_history\": copy.deepcopy(context),\n",
    "                \"query\": text,\n",
    "                \"path_history\": copy.deepcopy(path_history),\n",
    "                \"current_entity\": data_loader.entity2num[ce],\n",
    "                \"current_entity_str\": ce,\n",
    "                \"target_entity\": data_loader.entity2num[te],\n",
    "                \"target_entity_str\": te,\n",
    "                \"step\": len(path)\n",
    "            }\n",
    "            if option.instruction_type == \"0\":\n",
    "                temp_input = inputs.format(sample[\"dialog_history\"], sample[\"query\"], sample[\"path_history\"], ce, 1, '')\n",
    "                final_prompt = alpaca_format.format(instruction=instruction, input=temp_input)\n",
    "                sample[\"input\"] = final_prompt\n",
    "            elif option.instruction_type == \"1\":\n",
    "                sample[\"input\"] = normal_prompt.format(sample[\"dialog_history\"], sample[\"query\"], sample[\"path_history\"], ce, 1, '')\n",
    "            else:\n",
    "                sample[\"input\"] = inputs.format(context, text, path_history, ce, 1, '')\n",
    "            input_len = len(sample[\"input\"])\n",
    "            lens.append(input_len)\n",
    "            if input_len <= rl_lens_threshold:\n",
    "                # if len(path) == 2:\n",
    "                #     for i in range(3):\n",
    "                #         path_len_distribution[1] += 1\n",
    "                #         rl_data.append(copy.deepcopy(sample))\n",
    "                # else:\n",
    "                path_len_distribution[len(path)-1] += 1\n",
    "                # rl_data.append(copy.deepcopy(sample))\n",
    "                # rl_data.append(copy.deepcopy(sample))\n",
    "                path_num = []\n",
    "                for p in path:\n",
    "                    h_ = p[0].strip()\n",
    "                    r_ = p[1].strip()\n",
    "                    t_ = p[2].strip()\n",
    "                    path_num.append([data_loader.entity2num[h_], data_loader.relation2num[r_], data_loader.entity2num[t_]])\n",
    "                if len(path) == 1:\n",
    "                    h_ = te\n",
    "                    r_ = \"Equal\"\n",
    "                    t_ = te\n",
    "                    path_num.append([data_loader.entity2num[h_], data_loader.relation2num[r_], data_loader.entity2num[t_]])\n",
    "                    # rl_data_len_path_2.append(copy.deepcopy(sample))\n",
    "                # else:\n",
    "                    # rl_data_len_path_1.append(copy.deepcopy(sample))\n",
    "                sample[\"path\"] = path_num\n",
    "                rl_data.append(copy.deepcopy(sample))\n",
    "                \n",
    "                if len(path) == 2:\n",
    "                    rl_data_len_path_2.append(copy.deepcopy(sample))\n",
    "                else:\n",
    "                    rl_data_len_path_1.append(copy.deepcopy(sample))\n",
    "                    \n",
    "        if \"current_entity\" in item.keys() and sender == \"assistant\":\n",
    "            user_path = item[\"path\"]\n",
    "            for u_p in user_path:\n",
    "                u_p_str = ','.join(u_p)\n",
    "                path_history.append(u_p_str)\n",
    "        context.append(f\"{sender}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2eaa3b-d01c-410d-b9dc-05e993819f83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14972"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rl_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe906b-267e-49c0-a64e-6c7fb046a811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(data, gamma):\n",
    "    train_size=int(gamma*len(data))\n",
    "    # print(train_size)\n",
    "    test_size=len(data) - train_size\n",
    "    # print(test_size)\n",
    "    train_dataset, test_dataset=torch.utils.data.random_split(data,[train_size, test_size])\n",
    "    return list(train_dataset), list(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830793c-567f-406a-85ad-474af1f880f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len_path_1_train_dataset, len_path_1_test_dataset =  split_dataset(rl_data_len_path_1, 0.85)\n",
    "\n",
    "# len_path_2_train_dataset, len_path_2_test_dataset =  split_dataset(rl_data_len_path_2, 0.85)\n",
    "\n",
    "# rl_train_dataset = len_path_1_train_dataset + len_path_2_train_dataset\n",
    "# rl_test_dataset = len_path_1_test_dataset + len_path_2_test_dataset\n",
    "\n",
    "np.random.seed(option.seed)\n",
    "np.random.shuffle(rl_data)\n",
    "\n",
    "rl_train_dataset, rl_test_val_dataset = split_dataset(rl_data, 0.7)\n",
    "\n",
    "len_test_dataset = len(rl_test_val_dataset) // 2\n",
    "\n",
    "rl_valid_dataset = rl_test_val_dataset[:len_test_dataset]\n",
    "\n",
    "rl_test_dataset = rl_test_val_dataset[len_test_dataset:]\n",
    "\n",
    "with open(option.rl_train_data_path, \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(rl_train_dataset, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(option.rl_valid_data_path, \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(rl_valid_dataset, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "with open(option.rl_test_data_path, \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(rl_test_dataset, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247bbf3-e1cb-4467-b0f3-4dcb625c36a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
